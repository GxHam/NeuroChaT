{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "sys.path.insert(1, r'C:\\Users\\smartin5\\Repos\\myNeurochat')\n",
    "#sys.path.insert(1, r'C:\\Users\\maolivei\\neuro_sean\\NeuroChaT')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurochat.nc_spike import NSpike\n",
    "from neurochat.nc_spatial import NSpatial\n",
    "from neurochat.nc_data import NData\n",
    "from neurochat.nc_datacontainer import NDataContainer\n",
    "import neurochat.nc_plot as nc_plot\n",
    "import neurochat.nc_containeranalysis as nca\n",
    "from neurochat.nc_clust import NClust\n",
    "from neurochat.nc_utils import butter_filter\n",
    "from neurochat.nc_utils import find_peaks\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the main data path\n",
    "home = os.path.expanduser(\"~\")\n",
    "data_dir = os.path.join(\n",
    "    home, \"Recordings\", \"LCA1\")\n",
    "prepend_data_dir = lambda name : os.path.join(data_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\"\"\"\n",
    "spike_filenames = [\n",
    "    \"LCA1-linearpresleep30min050319.2\",\n",
    "    \"050319D_LCA1_linear_10min.2\",\n",
    "    \"LCA1-linearpresleep_40min050319_B.2\"]\n",
    "\"\"\"\n",
    "\n",
    "spike_filenames = [\n",
    "#    \"LCA1-linearpresleep30min060319.2\",\n",
    "    \"060319D_LCA1_linear_15min.2\",\n",
    "    \"060319E_LCA1_linear_sleep_32min.2\"]\n",
    "\n",
    "spike_absolute_filenames = [prepend_data_dir(name) for name in spike_filenames]\n",
    "\n",
    "spike_names = [\n",
    "#    \"pre-sleep\",\n",
    "    \"run\",\n",
    "    \"post-sleep\"]\n",
    "\n",
    "position_absolute_filenames = [f[:-2] + \".txt\" for f in spike_absolute_filenames]\n",
    "\n",
    "lfp_end = \".egf\"\n",
    "\n",
    "lfp_absolute_filenames = [f[:-2] + lfp_end for f in spike_absolute_filenames]\n",
    "\n",
    "collection = NDataContainer(share_positions=False, load_on_fly=True)\n",
    "collection.add_files(\n",
    "    NDataContainer.EFileType.Spike, (spike_absolute_filenames, spike_names, None))\n",
    "collection.add_files(\n",
    "    NDataContainer.EFileType.LFP, lfp_absolute_filenames\n",
    ")\n",
    "collection.add_files(\n",
    "    NDataContainer.EFileType.Position, position_absolute_filenames)\n",
    "\n",
    "collection.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.list_all_units()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to identify the same units\n",
    "nclust1 = NClust()\n",
    "nclust2 = NClust()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the appropriate units\n",
    "# collection.set_units([\"all\", \"all\"])\n",
    "run_units = [2, 3, 4] # top, middle, bottom\n",
    "sleep_units = [2, 3, 4, 6, 7, 8] # Units from powerpoint file\n",
    "collection.set_units([run_units, sleep_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_clust = nca.evaluate_clusters(collection, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_units = [val[0] for _, val in eval_clust.items()]\n",
    "collection.set_units([run_units, best_units])\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.set_units([run_units, [4, 6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum plot\n",
    "graph_data = collection.get_data(1).lfp.spectrum(\n",
    "    window = 0.4, noverlap = 0.04, nfft = 2048, ptype = 'psd', \n",
    "    prefilt = True, filtset = [10, 100, 'highpass'], \n",
    "    fmax = 2400, db = False, tr = False, slice=slice(0, 9600, 1))\n",
    "fig = nc_plot.lfp_spectrum(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size, mode=\"same\"):\n",
    "    \"\"\"\n",
    "    Calculates the rms envelope, similar to matlab - mode determines how many points are output\n",
    "    mode valid will have no border effects, while same will produce a value for each input\n",
    "    \"\"\"\n",
    "    a2 = np.power(a,2)\n",
    "    window = np.ones(window_size)/float(window_size)\n",
    "    return np.sqrt(np.convolve(a2, window, mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_window_rms(x, N):\n",
    "    \"\"\"\n",
    "    Calculates the rms of x in windows of N data points\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x = np.square(x) / float(N)\n",
    "    rms_array = []\n",
    "    rms = 0\n",
    "    \n",
    "    # For now, just throw away the last window if it does not fit\n",
    "    for idx, point in enumerate(x):\n",
    "        rms += point\n",
    "        if idx % N == N-1:\n",
    "            rms_array.append(np.sqrt(rms))\n",
    "            rms = 0\n",
    "    return rms_array\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the filtered data\n",
    "fs = collection.get_data(1).get_sampling_rate()\n",
    "num_samples = 1200\n",
    "lfp_samples = collection.get_data(1).get_samples()[:num_samples]\n",
    "time = collection.get_data(1).lfp.get_timestamp()\n",
    "filtered_lfp = butter_filter(lfp_samples, fs, 10, 100, 240, 'bandpass') # SWR\n",
    "#rms_data = window_rms(filtered_lfp, 33, \"same\")\n",
    "ax, fig = nc_plot._make_ax_if_none(None)\n",
    "ax.plot(time[:num_samples], filtered_lfp, color='r')\n",
    "ax.plot(time[:num_samples], lfp_samples, color='b')\n",
    "#ax.plot(time[:num_samples], rms_data, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs some extra work to better deal with overlapping intervals, use distinct for now to combat this\n",
    "# Could use the derivative to find the peaks - see nc_utils.py commented out - combine this with percentile\n",
    "run = collection.get_data(1)\n",
    "run.set_unit_no(1)\n",
    "sleep_lfps = np.array(run.non_moving_periods(min_range=150, moving_thresh=2.5)) * 4800\n",
    "sample_start = sleep_lfps[1]\n",
    "lfp_samples = run.get_samples()[int(sample_start[0]):int(sample_start[1])]\n",
    "filtered_lfp = butter_filter(lfp_samples, fs, 10, 120, 240, 'bandpass')\n",
    "rms_window_size = 33 # 0.007 / (1/4800)\n",
    "rms_data = distinct_window_rms(filtered_lfp, rms_window_size) # 7ms windows\n",
    "p99 = np.percentile(rms_data, 99)\n",
    "peaks = (sample_start[0] + np.argwhere(rms_data > p99).flatten() * rms_window_size) / 4800\n",
    "\n",
    "from neurochat.nc_utils import find_peaks\n",
    "_, peaks2 = find_peaks(rms_data, thresh=p99)\n",
    "peaks2 = (sample_start[0] + peaks2 * rms_window_size) / 4800\n",
    "\n",
    "window = 0.20 # 400ms windows\n",
    "ranges = [(i - window, i + window) for i in peaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [run.non_moving_periods(min_range=150, moving_thresh=2.5)[1]]\n",
    "hist = nca.multi_unit_activity(collection.subsample(1), ranges=ranges, bin_length=1, min_range=0.1, should_smooth=True, mode=2)\n",
    "plt.bar(hist['bin_centres'][0], hist['hists'][0])\n",
    "sleep = collection.subsample(1)\n",
    "# TODO need to sort the run spatially and line the sleep up with this - also need better mua, can look at histogram of uniques\n",
    "sleep.sort_units_spatially(mode=\"vertical\")\n",
    "fig = nc_plot.spike_time_raster(nca.spike_times(sleep, ranges=hist['mua'][0]), linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate out the things from the synaptic paper - should be self contained\n",
    "sleep = collection.get_data(1)\n",
    "sleep_lfps = np.array(sleep.non_moving_periods(min_range=150, moving_thresh=2.5)) * 4800\n",
    "sample_start = sleep_lfps[1]\n",
    "\n",
    "fs = collection.get_data(1).get_sampling_rate()\n",
    "lfp_samples = collection.get_data(1).get_samples()[int(sample_start[0]):int(sample_start[1])]\n",
    "time = collection.get_data(1).lfp.get_timestamp()[int(sample_start[0]):int(sample_start[1])]\n",
    "filtered_lfp = butter_filter(lfp_samples, fs, 10, 100, 250, 'bandpass')\n",
    "rms_window_size = 33 # 7ms\n",
    "rms_data = distinct_window_rms(filtered_lfp, rms_window_size)\n",
    "p99 = np.percentile(rms_data, 99)\n",
    "peaks = (sample_start[0] + np.argwhere(rms_data > p99).flatten() * rms_window_size) / 4800\n",
    "# This detects the up and down peaks together - probably not desirable\n",
    "_, peaks2 = find_peaks(rms_data, thresh=p99)\n",
    "peaks2 = (sample_start[0] + peaks2 * rms_window_size) / 4800\n",
    "unit_hist = nca.count_units_in_bins(collection.subsample(1), 1, sample_start / 4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection)\n",
    "collection.sort_units_spatially([True, False], mode=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,3))\n",
    "nc_plot.spike_time_raster(nca.spike_times(collection.subsample(0), ranges=[(200, 300)], linewidths=0.1), ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the above nicely\n",
    "fig, axes= plt.subplots(nrows=3, ncols=1, figsize=(12,6), sharex=True)\n",
    "colors = ('r', 'g', 'b')\n",
    "xlim = sample_start / 4800\n",
    "nc_plot.spike_raster(peaks2, ax=axes[0], title=\"SWR events\", ylabel=None, xlabel=None, no_y_ticks=True, colors=('b'), linewidths=0.2, linelengths=0.5) # SWR\n",
    "axes[0].plot(time, filtered_lfp, color='k') # filtered LFP\n",
    "axes[0].set_title(\"Filtered LFP and SWR\")\n",
    "axes[1].bar(unit_hist[1], unit_hist[0], width=1, color='k') # MUA\n",
    "axes[1].set_yticks((0, 1, 2, 3))\n",
    "axes[1].set_title(\"Number of Active Cells\")\n",
    "nc_plot.spike_raster(nca.spike_times(collection.subsample(1), ranges=[sample_start / 4800]), linewidths=0.2, ax=axes[2], colors=colors) # Raw spikes\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "tick_spacing = 100\n",
    "for ax in axes:\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"output.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an areas of interest\n",
    "sleep_samp = collection.subsample(1)\n",
    "mua_indices = np.argwhere(unit_hist[0] == 3)\n",
    "interest_ranges = []\n",
    "for mua in [unit_hist[1][j] for j in mua_indices.flatten()]:\n",
    "    # Is the centre lying in a SWR\n",
    "    if any(\n",
    "        mua - 0.5 <= peak - 0.4 <= mua + 0.5 or\n",
    "        mua - 0.5 <= peak + 0.4 <= mua + 0.5\n",
    "        for peak in peaks2\n",
    "    ):\n",
    "        interest_ranges.append((mua - 0.5, mua + 0.5)) # 1sec bins\n",
    "\n",
    "# Plot the interest ranges\n",
    "for mua in [unit_hist[1][j] for j in mua_indices.flatten()]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,3))\n",
    "    nc_plot.spike_raster(nca.spike_times(sleep_samp, ranges=[(mua - 0.5, mua + 0.5)]), linewidths=1, ax=ax, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the interest ranges\n",
    "for interest_range in interest_ranges:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,3))\n",
    "    nc_plot.spike_raster(nca.spike_times(sleep_samp, ranges=[interest_range]), linewidths=1, ax=ax, colors=colors)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"raster.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interest_ranges)\n",
    "start = int(interest_ranges[1][0] *4800 - sample_start[0])\n",
    "end = int((interest_ranges[1][1] + 3) * 4800 - sample_start[0])\n",
    "plt.plot(time[start:end], filtered_lfp[start:end], color='k') # filtered LFP\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sleep = collection.get_data(0)\n",
    "lfp = pre_sleep.lfp.get_samples()\n",
    "ax, fig = nc_plot._make_ax_if_none(None)\n",
    "time = [i * (1 / pre_sleep.lfp.get_sampling_rate()) for i in range(len(lfp))]\n",
    "ax.plot(time[:19200], lfp[:19200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of spikes which occur when the rat is not moving\n",
    "# not_moving = pre_sleep.get_speed() < 3\n",
    "# count = 0\n",
    "# for i in not_moving:\n",
    "#     count += int(i)\n",
    "# print(count, len(not_moving)-count)\n",
    "# #not_moving_spikes = pre_sleep.spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(collection.get_num_data()):\n",
    "    run = collection.get_data(i)\n",
    "    run.smooth_speed()\n",
    "    ax, fig = nc_plot._make_ax_if_none(None)\n",
    "    ax.plot(run.spatial.get_time(), run.get_speed())\n",
    "    ax.set_xlim(0, run.get_recording_time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
